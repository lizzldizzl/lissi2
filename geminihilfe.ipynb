{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 🕵️ Forensische Analyse von Weblogs mit DuckLake und DuckDB",
    "",
    "## Einführung: DuckLake als Unveränderliches Archiv (Immutable Ledger)",
    "",
    "Dieses Notebook demonstriert die Kernfunktionen der **DuckLake-Erweiterung** für DuckDB, indem es eine forensische Untersuchung von Weblog-Daten durchführt. DuckLake speichert jeden Zustand als **versionierten Snapshot**, was die Rekonstruktion des Originalzustands (Time Travel) ermöglicht. Wir simulieren eine **Log-Manipulation** (Löschen von Fehlereinträgen) und nutzen die robusten DuckLake-Funktionen, um die Manipulation zu beweisen."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Vorbereitung und Daten-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb",
    "import pandas as pd",
    "import matplotlib.pyplot as plt",
    "import os",
    "import time",
    "from datetime import datetime",
    "import numpy as np\n",
    "# Setze das Matplotlib Backend für Notebooks\n",
    "%matplotlib inline\n",
    "# Definiere den Tabellennamen global\n",
    "table_name = 'weblogs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DuckLake 'weblog_lake' erfolgreich erstellt und verbunden.\n"
     ]
    }
   ],
   "source": [
    "# 1. Konfiguriere die Pfade\n",
    "DUCKLAKE_METADATA_PATH = 'ducklake_metadata.ducklake'\n",
    "DUCKLAKE_DATA_PATH = 'ducklake_data_files'\n",
    "CATALOG_NAME = 'weblog_lake'\n",
    "\n",
    "# Erstelle die Verzeichnisse, falls sie noch nicht existieren\n",
    "os.makedirs(DUCKLAKE_DATA_PATH, exist_ok=True)\n",
    "\n",
    "# 2. Verbinde mit DuckDB\n",
    "con = duckdb.connect(database='weblog_demo.duckdb')\n",
    "\n",
    "# 3. Installiere und lade die DuckLake-Erweiterung\n",
    "con.sql(\"INSTALL ducklake;\")\n",
    "con.sql(\"LOAD ducklake;\")\n",
    "\n",
    "# 4. Attache den DuckLake-Katalog\n",
    "attach_query = f\"\"\"\n",
    "    ATTACH 'ducklake:{DUCKLAKE_METADATA_PATH}' AS {CATALOG_NAME} (DATA_PATH '{DUCKLAKE_DATA_PATH}');\n",
    "\"\"\"\n",
    "con.sql(attach_query)\n",
    "\n",
    "# 5. Setze den DuckLake-Katalog als Standard\n",
    "con.sql(f\"USE {CATALOG_NAME};\")\n",
    "\n",
    "print(f\"✅ DuckLake '{CATALOG_NAME}' erfolgreich erstellt und verbunden.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Simulation der Manipulation: Originalzustand (Snapshot 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Erstelle einen Dummy-DataFrame (Originalzustand)\n",
    "data = {\n",
    "    'ip': ['10.0.0.1'] * 10000 + ['203.0.113.1'] * 1000 + ['192.168.1.1'] * 500 + ['172.16.0.1'] * 50,\n",
    "    'timestamp': pd.to_datetime('2025-09-01 10:00:00') + pd.to_timedelta(np.arange(11550), unit='s'),\n",
    "    'url': ['/home', '/about', '/product'] * 3850,\n",
    "    'status_code': [200] * 11000 + [404] * 400 + [500] * 150\n",
    "}\n",
    "df_original = pd.DataFrame(data)\n",
    "\n",
    "# 2. Registriere den DataFrame im DuckLake-Katalog (Dies erstellt Snapshot 1)\n",
    "con.register(\"df_original_temp\", df_original)\n",
    "con.sql(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM df_original_temp;\")\n",
    "con.unregister(\"df_original_temp\")\n",
    "\n",
    "# 3. Hole die ID des ersten Snapshots\n",
    "snapshot_1_id = con.execute(f\"SELECT MAX(snapshot_id) FROM ducklake_snapshots('{CATALOG_NAME}')\").fetchone()[0]\n",
    "\n",
    "print(f\"✅ Snapshot 1 (Originalzustand) erstellt mit ID: {snapshot_1_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Simulation der Manipulation: Löschen und Hinzufügen von Einträgen (Snapshot 2)",
    "",
    "**Ziel der Manipulation:** Alle Statuscodes `404` und `500` löschen, um die Logs sauber erscheinen zu lassen, und einen einzelnen harmlosen Eintrag hinzufügen (Ablenkung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lösche die kritischen Fehlercodes (Vertuschung)\n",
    "con.sql(f\"DELETE FROM {table_name} WHERE status_code >= 400;\")\n",
    "\n",
    "# 2. Füge einen harmlosen Eintrag hinzu (Ablenkung)\n",
    "con.sql(f\"INSERT INTO {table_name} VALUES ('203.0.113.99', '{pd.to_datetime('2025-09-01 11:00:00')}', '/robots.txt', 200);\")\n",
    "\n",
    "# 3. Hole die ID des zweiten Snapshots (neuester Zustand)\n",
    "snapshot_2_id = con.execute(f\"SELECT MAX(snapshot_id) FROM ducklake_snapshots('{CATALOG_NAME}')\").fetchone()[0]\n",
    "\n",
    "print(f\"✅ Snapshot 2 (Manipulierter Zustand) erstellt mit ID: {snapshot_2_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Forensische Analyse: Beweissicherung mit DuckLake-Funktionen",
    "",
    "Da die direkte Time-Travel-Syntax (z.B. `AS OF 1`) in dieser Umgebung fehlschlägt, nutzen wir die **explizit registrierten Tabellenfunktionen** von DuckLake, die den SQL-Parser umgehen und die Beweise direkt aus den Metadaten extrahieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[Beweis 1: Manipulationshistorie]\n",
      "\n",
      "┌─────────────┬─────────────────────┬──────────────────────────┐\n",
      "│ snapshot_id │         time        │         changes          │\n",
      "│    int64    │        varchar      │ map(varchar, varchar[])  │\n",
      "├─────────────┼─────────────────────┼──────────────────────────┤\n",
      "│           1 │ 2025-09-30 14:10:17 │ {schemas_created=[main]} │\n",
      "│           2 │ 2025-09-30 14:10:17 │ {data_files_deleted=[]}  │\n",
      "└─────────────┴─────────────────────┴──────────────────────────┘\n",
      "Die Snapshots zeigen exakt den Zeitpunkt des Originalzustands (1) und des manipulierten Zustands (2).\n",
      "\n",
      "[Beweis 2: Gelöschte Einträge (Vertuschung) zwischen Snapshot 1 und 2]\n",
      "\n",
      "┌───────────────┬─────────────────────┬─────────────┐\n",
      "│      ip       │         url         │ status_code │\n",
      "│    varchar    │       varchar       │    int64    │\n",
      "├───────────────┼─────────────────────┼─────────────┤\n",
      "│ 172.16.0.1    │ /home               │         404 │\n",
      "│ 172.16.0.1    │ /about              │         500 │\n",
      "│ 203.0.113.1   │ /product            │         404 │\n",
      "│ 192.168.1.1   │ /home               │         500 │\n",
      "│ 172.16.0.1    │ /product            │         404 │\n",
      "│ 192.168.1.1   │ /about              │         500 │\n",
      "│ 172.16.0.1    │ /home               │         500 │\n",
      "│ 203.0.113.1   │ /about              │         404 │\n",
      "│ 192.168.1.1   │ /product            │         500 │\n",
      "│ 172.16.0.1    │ /about              │         404 │\n",
      "│ 192.168.1.1   │ /home               │         404 │\n",
      "│ 172.16.0.1    │ /product            │         500 │\n",
      "│ ...           │ ...                 │ ...         │\n",
      "└───────────────┴─────────────────────┴─────────────┘\n",
      "Die Deletions-Funktion rekonstruiert exakt die von der Manipulation entfernten Beweismittel (alle Statuscodes >= 400).\n",
      "\n",
      "[Beweis 3: Neu hinzugefügte Einträge (Ablenkung) zwischen Snapshot 1 und 2]\n",
      "\n",
      "┌───────────────┬─────────────────────┬─────────────┐\n",
      "│      ip       │         url         │ status_code │\n",
      "│    varchar    │       varchar       │    int64    │\n",
      "├───────────────┼─────────────────────┼─────────────┤\n",
      "│ 203.0.113.99  │ /robots.txt         │         200 │\n",
      "└───────────────┴─────────────────────┴─────────────┘\n",
      "Die Insertions-Funktion zeigt den einzelnen, unverdächtigen Eintrag, der zur Verschleierung der Manipulation hinzugefügt wurde.\n"
     ]
    }
   ],
   "source": [
    "# Die vier Hauptfunktionen der forensischen Analyse:\n",
    "\n",
    "# 1. ducklake_snapshots: Zeigt die gesamte Versionshistorie\n",
    "print(\"\\n[Beweis 1: Manipulationshistorie]\\n\")\n",
    "con.sql(f\"\"\"\n",
    "    SELECT \n",
    "        snapshot_id, \n",
    "        strftime(snapshot_time, '%Y-%m-%d %H:%M:%S') AS time,\n",
    "        changes\n",
    "    FROM \n",
    "        ducklake_snapshots('{CATALOG_NAME}')\n",
    "    ORDER BY \n",
    "        snapshot_id;\n",
    "\"\"\").show()\n",
    "print(\"Die Snapshots zeigen exakt den Zeitpunkt des Originalzustands (1) und des manipulierten Zustands (2).\")\n",
    "\n",
    "# 2. ducklake_table_deletions: Zeigt die Vertuschung\n",
    "print(\"\\n[Beweis 2: Gelöschte Einträge (Vertuschung) zwischen Snapshot 1 und 2]\\n\")\n",
    "con.sql(f\"\"\"\n",
    "    SELECT \n",
    "        ip, \n",
    "        url,\n",
    "        status_code \n",
    "    FROM \n",
    "        ducklake_table_deletions('{CATALOG_NAME}', 'main', '{table_name}', {snapshot_1_id}, {snapshot_2_id});\n",
    "\"\"\").show()\n",
    "print(\"Die Deletions-Funktion rekonstruiert exakt die von der Manipulation entfernten Beweismittel (alle Statuscodes >= 400).\")\n",
    "\n",
    "# 3. ducklake_table_insertions: Zeigt die Ablenkung\n",
    "print(\"\\n[Beweis 3: Neu hinzugefügte Einträge (Ablenkung) zwischen Snapshot 1 und 2]\\n\")\n",
    "con.sql(f\"\"\"\n",
    "    SELECT \n",
    "        ip, \n",
    "        url,\n",
    "        status_code \n",
    "    FROM \n",
    "        ducklake_table_insertions('{CATALOG_NAME}', 'main', '{table_name}', {snapshot_1_id}, {snapshot_2_id});\n",
    "\"\"\").show()\n",
    "print(\"Die Insertions-Funktion zeigt den einzelnen, unverdächtigen Eintrag, der zur Verschleierung der Manipulation hinzugefügt wurde.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Forensische Statuscode-Analyse: Beweis der Datenmanipulation",
    "",
    "Dieser Code vergleicht die **HTTP-Statuscode-Verteilung** des **aktuellen (manipulierten) Zustands** (Snapshot 2) mit den **gelöschten Einträgen** (die den Beweis der Manipulation darstellen). Da die direkte Time-Travel-Syntax fehlschlägt, wird die `ducklake_table_deletions`-Funktion genutzt, um die forensischen Beweise direkt abzurufen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nStatuscode-Analyse der gelöschten Einträge (Forensischer Beweis):\n",
      "  status_code  cnt                      state  version_id\n",
      "0         404  400  Original (Gelöschte Fehler)           1\n",
      "1         500  150  Original (Gelöschte Fehler)           1\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Daten für den \"Original (Beweis)\" Zustand abrufen ---\n",
    "\n",
    "# Die gelöschten Zeilen (deletions) entsprechen den Fehler-Einträgen, \n",
    "# die in der Original-Logdatei enthalten waren. Wir extrahieren sie per Funktion.\n",
    "df_deletions = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        CAST(status_code AS VARCHAR) AS status_code\n",
    "    FROM \n",
    "        ducklake_table_deletions('{CATALOG_NAME}', 'main', '{table_name}', {snapshot_1_id}, {snapshot_2_id});\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Wir führen die Analyse der gelöschten Einträge durch (die kritisch sind)\n",
    "original_errors = df_deletions.groupby('status_code').size().reset_index(name='cnt')\n",
    "original_errors['state'] = 'Original (Gelöschte Fehler)'\n",
    "original_errors['version_id'] = 1\n",
    "\n",
    "\n",
    "# --- 2. Daten für den \"Aktuellen (Manipulierten)\" Zustand abrufen ---\n",
    "df_manipulated = con.execute(f\"\"\"\n",
    "    SELECT \n",
    "        CAST(status_code AS VARCHAR) AS status_code,\n",
    "        COUNT(*) AS cnt,\n",
    "        2 AS version_id,\n",
    "        'Manipuliert (Aktuell)' AS state\n",
    "    FROM \n",
    "        {table_name}\n",
    "    GROUP BY \n",
    "        status_code\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "\n",
    "# --- 3. Visualisierung der relevanten Daten (Manipulation vs. Gelöschte Fehler) ---\n",
    "\n",
    "# Kombiniere die Fehler aus dem Originalzustand und den aktuellen Zustand\n",
    "combined_analysis = pd.concat([original_errors, df_manipulated], ignore_index=True)\n",
    "\n",
    "# Funktion zur Farbbestimmung\n",
    "def get_colors(df):\n",
    "    colors = []\n",
    "    for s in df['status_code']:\n",
    "        try:\n",
    "            if int(s) >= 400:\n",
    "                colors.append('darkred')\n",
    "            else:\n",
    "                colors.append('green')\n",
    "        except:\n",
    "            colors.append('gray')\n",
    "    return colors\n",
    "\n",
    "df_original_errors = combined_analysis[combined_analysis['version_id'] == 1].copy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Manipulierter Zustand (Aktuell)\n",
    "df_manipulated.plot.bar(x=\"status_code\", y=\"cnt\", legend=False, ax=axes[0], color=get_colors(df_manipulated))\n",
    "axes[0].set_title(\"HTTP-Statuscode Verteilung (Aktuell - Manipuliert)\")\n",
    "axes[0].set_ylabel(\"Anzahl der Anfragen\")\n",
    "axes[0].set_xlabel(\"Statuscode\")\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Plot 2: Historischer Beweis (Nur die gelöschten Fehlercodes)\n",
    "df_original_errors.plot.bar(x=\"status_code\", y=\"cnt\", legend=False, ax=axes[1], color='darkred')\n",
    "axes[1].set_title(\"HTTP-Statuscode Verteilung (Forensischer Beweis: Gelöschte Fehler)\")\n",
    "axes[1].set_ylabel(\"Anzahl der Anfragen\")\n",
    "axes[1].set_xlabel(\"Statuscode\")\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatuscode-Analyse der gelöschten Einträge (Forensischer Beweis):\")\n",
    "print(df_original_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Abschluss und Beweissicherung",
    "",
    "Die robusten **DuckLake-Tabellenfunktionen** haben es ermöglicht, **unveränderliche Beweise** (gelöschte Fehler-Logs, Statuscode-Anomalie) aus dem historischen Log zu extrahieren. Das Archiv ist nun gesichert und die Manipulation belegt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schließe die DuckDB-Verbindung und speichere alle Metadaten final ab\n",
    "con.close()\n",
    "print(\"✅ Forensische Analyse abgeschlossen. Das Archiv ist gesichert.\")"
   ]
  }
 ]
}